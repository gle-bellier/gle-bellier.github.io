[{"categories":null,"contents":"As summer approaches, I am pleased to share my reading list for the season. This compilation is designed to encompass papers that are closely aligned with my research interests, while also including a diverse range of topics (curiosity). If you have any papers you’ve enjoyed—old or new—please share them with me on Twitter or via email. Happy reading!\nSelf-Supervised Learning with Lie Symmetries for Partial Differential Equations, Mialon et al Link\nEM Distillation for One-step Diffusion Models, Xie et al. Link\nOmniSat: Self-Supervised Modality Fusion for Earth Observation, Astruc et al. Link\nCross-sensor self-supervised training and alignment for remote sensing, Marsocci et al. Link\nOpen-Canopy: A Country-Scale Benchmark for Canopy Height Estimation at Very High Resolution, Fogel et al. Link\nGromov-Wasserstein Averaging of Kernel and Distance Matrices, Peyre et al. Link\nContext-Guided Diffusion for Out-of-Distribution Molecular and Protein Design, Klarner et al. Link\nNeural Optimal Transport with Lagrangian Costs, Liang-Chieh Chen et al. Link\nSpace-Time Continuous PDE Forecasting using Equivariant Neural Fields, Knigge et al. Link\nFoundation Models for Generalist Geospatial Artificial Intelligence, Jakubik et al. Link\nSTONE: Self-Supervised Tonality Estimator, Kong et al. Link\nThe Mathematics of Emergence, Cucker et al. Link\nGenerative Data Assimilation of Sparse Weather Station Observations at Kilometer Scales, Manshausen et al. Link\nFlow Map Matching, Boffi et al. Link\nLearning Diffusion at Lightspeed, Terpin et al. Link\n3D Gaussian Splatting for Real-Time Radiance Field Rendering, Kerbl et al. Link\nSimplified and Generalized Masked Diffusion for Discrete Data, Shi et al. Link\nChameleon: Mixed-Modal Early-Fusion Foundation Models, Chameleon Team. Link\nEstimating Canopy Height at Scale, Pauls et al. Link\nGenerating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees, Jolicoeur-Martineau et al. Link\nNeural Operators with Localized Integral and Differential Kernels, Liu-Schiaffini et al. Link\nD-Flow: Differentiating through Flows for Controlled Generation, Ben-Hamu et al. Link\n","date":"Jul 18","permalink":"https://gle-bellier.github.io/posts/readinglist/","tags":null,"title":"[Reading List] Summer"},{"categories":null,"contents":" Experience Ph.D. Student (Conservatoire National des Arts et Metiers) January 2023 - Now Paris Ph.D. student working on domain adaptation and self-supervised learning for earth observation, as part of the ANR MAGE (Mapping Aerial imagery with Game Engine data) at Conservatoire National des Arts et Métiers. Supervised by Nicolas Audebert (IGN, CNAM), Nicolas Thome (Sorbonne University), Marin Ferecatu (CNAM). Research Traineeship (Sony CSL) April 2022 - September 2022 Paris Research traineeship on Diffusion Models applied to expressive musical performances generation. I focused on controllable generation with conditional generation methods. I achieved bibliographical research on the state of the art, implemented various deep learning models and trained them. \u0026ndash; Code Research Project (IRCAM) September 2021 - March 2022 Research project as part of the Centrale Lille research program. We use deep-learning models for music performance modeling. I designed and trained generative adversarial networks (GANs) for this purpose. The sound synthesis relies on Google Magenta\u0026rsquo;s DDSP model, the core of our problem was then the modeling of the expressive time-series of fundamental frequency and loudness. This work was accompanied by a report and a technical defense submitted to a jury. \u0026ndash; Code Research Traineeship (IRCAM-Pixtunes) March 2021 - September 2021 Paris Research internship in the ACIDS research team (IRCAM) in connection with the company Pixtunes GmbH. Research and implementation of Machine Learning algorithms for expressive playback of midi files using the DDSP (Differentiable Digital Signal Processing) model. In addition, I did a bibliographic research on the field and prepared two different datasets. During this internship I used the pytorch framework (and pytorch-lightning) and I focused on autoregressive approches and Denoising Diffusion Probabilistic Models (DDPM). \u0026ndash; Code Research Traineeship (INRIA) January 2019 - February 2019 I carried out an internship in a research team in computer sciences named LINKS from Inria laboratories. I was selected to draft a summary of a research paper entitled “Incomplete Data: What Went Wrong, and How to Fix It” written by Leonid Libkin, University of Edinburgh. Education Ecole Centrale de Lille (M.Sc.) September 2018 - September 2022 Machine Learning, Data Science, Deep Learning, Signal processing, Acoustics, Computer science, Artificial intelligence, Multi-agent systems, Telecommunication systems, Electronics, Sociology of organisations, Project management. ATIAM Master Degree (M.Sc.) September 2020 - September 2021 Second year of Master’s Degree in sciences applied to musical applications. Core subjects are : Signal Processing, Acoustics, Machine Learning, Deep Learning, NMF, Data Science for Music, MIR. CPGE MPSI-MP September 2016 - September 2018 2-year advanced undergraduate studies in Mathematics, Physics and Computer Sciences. The main purposes of these classes is to develop methods and acquire scientific knowledge and prepare for the nationwide competitive examinations for the entry to the top engineering schools in France. ","date":"Feb 10","permalink":"https://gle-bellier.github.io/aboutme/","tags":null,"title":"About Me"},{"categories":null,"contents":"","date":"Jan 01","permalink":"https://gle-bellier.github.io/articles/","tags":null,"title":"Articles"}]